---
title: 'Momentum Transformer: Closing the Performance Gap Between Self-attention and
  Its Linearization'
abstract: Transformers have achieved remarkable success in sequence modeling and beyond
  but suffer from quadratic computational and memory complexities with respect to
  the length of the input sequence. Leveraging techniques include sparse and linear
  attention and hashing tricks; efficient transformers have been proposed to reduce
  the quadratic complexity of transformers but significantly degrade the accuracy.
  In response, we first interpret the linear attention and residual connections in
  computing the attention map as gradient descent steps. We then introduce momentum
  into these components and propose the \emph{momentum transformer}, which utilizes
  momentum to improve the accuracy of linear transformers while maintaining linear
  memory and computational complexities. Furthermore, we develop an adaptive strategy
  to compute the momentum value for our model based on the optimal momentum for quadratic
  optimization. This adaptive momentum eliminates the need to search for the optimal
  momentum value and further enhances the performance of the momentum transformer.
  A range of experiments on both autoregressive and non-autoregressive tasks, including
  image generation and machine translation, demonstrate that the momentum transformer
  outperforms popular linear transformers in training efficiency and accuracy.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nguyen22a
month: 0
tex_title: 'Momentum Transformer: Closing the Performance Gap Between Self-attention
  and Its Linearization'
firstpage: 189
lastpage: 204
page: 189-204
order: 189
cycles: false
bibtex_author: Nguyen, Tan Minh and Baraniuk, Richard and Kirby, Robert and Osher,
  Stanley and Wang, Bao
author:
- given: Tan Minh
  family: Nguyen
- given: Richard
  family: Baraniuk
- given: Robert
  family: Kirby
- given: Stanley
  family: Osher
- given: Bao
  family: Wang
date: 2022-09-14
address:
container-title: Proceedings of Mathematical and Scientific Machine Learning
volume: '190'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 9
  - 14
pdf: https://proceedings.mlr.press/v190/nguyen22a/nguyen22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

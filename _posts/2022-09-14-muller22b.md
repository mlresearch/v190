---
title: Notes on Exact Boundary Values in Residual Minimisation
abstract: We analyse the difference in convergence mode using exact versus penalised
  boundary values for the residual minimisation of PDEs with neural network type ansatz
  functions, as is commonly done in the context of physics informed neural networks.
  It is known that using an $L^2$ boundary penalty leads to a loss of regularity of
  $3/2$ meaning that approximation in $H^2$ yields a posteriori estimates in $H^{1/2}$.
  These notes demonstrate how this loss of regularity can be circumvented if the functions
  in the ansatz class satisfy the boundary values exactly. Furthermore, it is shown
  that in this case, the loss function provides a consistent a posteriori error estimator
  in $H^2$ norm made by the residual minimisation method. We provide analogue results
  for linear time dependent problems and discuss the implications of measuring the
  residual in Sobolev norms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: muller22b
month: 0
tex_title: Notes on Exact Boundary Values in Residual Minimisation
firstpage: 231
lastpage: 240
page: 231-240
order: 231
cycles: false
bibtex_author: M\"{u}ller, Johannes and Zeinhofer, Marius
author:
- given: Johannes
  family: MÃ¼ller
- given: Marius
  family: Zeinhofer
date: 2022-09-14
address:
container-title: Proceedings of Mathematical and Scientific Machine Learning
volume: '190'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 9
  - 14
pdf: https://proceedings.mlr.press/v190/muller22b/muller22b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

---
title: Stochastic and Private Nonconvex Outlier-Robust PCAs
abstract: We develop theoretically guaranteed stochastic methods for outlier-robust
  PCA. Outlier-robust PCA seeks an underlying low-dimensional linear subspace from
  a dataset that is corrupted with outliers. We are able to show that our methods,
  which involve stochastic geodesic gradient descent over the Grassmannian manifold,
  converge and recover an underlying subspace in various regimes through the development
  of a novel convergence analysis. The main application of this method is an effective
  differentially private algorithm for outlier-robust PCA that uses a Gaussian noise
  mechanism within the stochastic gradient method. Our results emphasize the advantages
  of the nonconvex methods over another convex approach to solving this problem in
  the differentially private setting. Experiments on synthetic and stylized data verify
  these results.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: maunu22a
month: 0
tex_title: Stochastic and Private Nonconvex Outlier-Robust PCAs
firstpage: 173
lastpage: 188
page: 173-188
order: 173
cycles: false
bibtex_author: Maunu, Tyler and Yu, Chenyu and Lerman, Gilad
author:
- given: Tyler
  family: Maunu
- given: Chenyu
  family: Yu
- given: Gilad
  family: Lerman
date: 2022-09-14
address:
container-title: Proceedings of Mathematical and Scientific Machine Learning
volume: '190'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 9
  - 14
pdf: https://proceedings.mlr.press/v190/maunu22a/maunu22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
